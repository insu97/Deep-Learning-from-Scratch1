{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNLDLQ/epTkGjd/eHKFXyFU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/insu97/Deep-Learning-from-Scratch1/blob/main/06_%ED%95%99%EC%8A%B5_%EA%B4%80%EB%A0%A8_%EA%B8%B0%EC%88%A0%EB%93%A4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W5BO9w_mGAoK",
        "outputId": "1c6866f5-a01c-4fdd-b3a4-d0054dbee0f0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd '/content/drive/MyDrive/Deep-Learning-from-Scratch/01/'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UXsJtL5bGBB-",
        "outputId": "266e2406-8785-412f-fb8c-1424926c1e72"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Deep-Learning-from-Scratch/01\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "ZvWIkrUccwqR"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 매개변수 갱신"
      ],
      "metadata": {
        "id": "96VOSgrVdaZl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 확률적 경사 하강법(SGD)"
      ],
      "metadata": {
        "id": "m0DsRrNy_UMu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SGD:\n",
        "    def __init__(self, lr=0.01):\n",
        "        self.lr = lr\n",
        "\n",
        "    def update(self, params, grads):\n",
        "        for key in params.keys():\n",
        "            params[key] -= self.lr * grads[key]"
      ],
      "metadata": {
        "id": "nX2ylx_DAJy4"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모멘텀"
      ],
      "metadata": {
        "id": "duIL1hjpARDn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Momentum:\n",
        "    def __init__(self, lr=0.01, momentum=0.9):\n",
        "        self.lr = lr\n",
        "        self.momentum = momentum\n",
        "        self.v = None\n",
        "\n",
        "    def update(self, params, grads):\n",
        "        if self.v is None:\n",
        "            self.v = {}\n",
        "            for key, val in params.items():\n",
        "                self.v[key] = np.zeros_like(val)\n",
        "\n",
        "        for key in params.keys():\n",
        "            self.v[key] = self.momentum * self.v[key] - self.lr * grads[key]\n",
        "            params[key] += self.v[key]"
      ],
      "metadata": {
        "id": "6ZouUaz1JDOn"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AdaGrad"
      ],
      "metadata": {
        "id": "0FpdhhxxMbAN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AdaGrad:\n",
        "    def __init__(self, lr=0.01):\n",
        "        self.lr = lr\n",
        "        self.h = None\n",
        "\n",
        "    def update(self, params, grads):\n",
        "        if self.h is None:\n",
        "            self.h = {}\n",
        "            for key, val in params.items():\n",
        "                self.h[key] = np.zeros_like(val)\n",
        "\n",
        "        for key in params.keys():\n",
        "            self.h[key] += grads[key] * grads[key]\n",
        "            params[key] -= self.lr * grads[key] / (np.sqrt(self.h[key]) + 1e-7)"
      ],
      "metadata": {
        "id": "d72upqWAa2T6"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adam"
      ],
      "metadata": {
        "id": "PhC8VaEpbHVz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Adam:\n",
        "\n",
        "    \"\"\"Adam (http://arxiv.org/abs/1412.6980v8)\"\"\"\n",
        "\n",
        "    def __init__(self, lr=0.001, beta1=0.9, beta2=0.999):\n",
        "        self.lr = lr\n",
        "        self.beta1 = beta1\n",
        "        self.beta2 = beta2\n",
        "        self.iter = 0\n",
        "        self.m = None\n",
        "        self.v = None\n",
        "\n",
        "    def update(self, params, grads):\n",
        "        if self.m is None:\n",
        "            self.m, self.v = {}, {}\n",
        "            for key, val in params.items():\n",
        "                self.m[key] = np.zeros_like(val)\n",
        "                self.v[key] = np.zeros_like(val)\n",
        "\n",
        "        self.iter += 1\n",
        "        lr_t  = self.lr * np.sqrt(1.0 - self.beta2**self.iter) / (1.0 - self.beta1**self.iter)\n",
        "\n",
        "        for key in params.keys():\n",
        "            #self.m[key] = self.beta1*self.m[key] + (1-self.beta1)*grads[key]\n",
        "            #self.v[key] = self.beta2*self.v[key] + (1-self.beta2)*(grads[key]**2)\n",
        "            self.m[key] += (1 - self.beta1) * (grads[key] - self.m[key])\n",
        "            self.v[key] += (1 - self.beta2) * (grads[key]**2 - self.v[key])\n",
        "\n",
        "            params[key] -= lr_t * self.m[key] / (np.sqrt(self.v[key]) + 1e-7)\n",
        "\n",
        "            #unbias_m += (1 - self.beta1) * (grads[key] - self.m[key]) # correct bias\n",
        "            #unbisa_b += (1 - self.beta2) * (grads[key]*grads[key] - self.v[key]) # correct bias\n",
        "            #params[key] += self.lr * unbias_m / (np.sqrt(unbisa_b) + 1e-7)"
      ],
      "metadata": {
        "id": "62XafndXbPHq"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Nesterov"
      ],
      "metadata": {
        "id": "4sblizqzco3T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Nesterov:\n",
        "\n",
        "    \"\"\"Nesterov's Accelerated Gradient (http://arxiv.org/abs/1212.0901)\"\"\"\n",
        "    # NAG는 모멘텀에서 한 단계 발전한 방법이다. (http://newsight.tistory.com/224)\n",
        "\n",
        "    def __init__(self, lr=0.01, momentum=0.9):\n",
        "        self.lr = lr\n",
        "        self.momentum = momentum\n",
        "        self.v = None\n",
        "\n",
        "    def update(self, params, grads):\n",
        "        if self.v is None:\n",
        "            self.v = {}\n",
        "            for key, val in params.items():\n",
        "                self.v[key] = np.zeros_like(val)\n",
        "\n",
        "        for key in params.keys():\n",
        "            self.v[key] *= self.momentum\n",
        "            self.v[key] -= self.lr * grads[key]\n",
        "            params[key] += self.momentum * self.momentum * self.v[key]\n",
        "            params[key] -= (1 + self.momentum) * self.lr * grads[key]"
      ],
      "metadata": {
        "id": "JJZe4iuXcjSE"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RMSprop"
      ],
      "metadata": {
        "id": "62tzOgQgcthy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RMSprop:\n",
        "\n",
        "    \"\"\"RMSprop\"\"\"\n",
        "\n",
        "    def __init__(self, lr=0.01, decay_rate = 0.99):\n",
        "        self.lr = lr\n",
        "        self.decay_rate = decay_rate\n",
        "        self.h = None\n",
        "\n",
        "    def update(self, params, grads):\n",
        "        if self.h is None:\n",
        "            self.h = {}\n",
        "            for key, val in params.items():\n",
        "                self.h[key] = np.zeros_like(val)\n",
        "\n",
        "        for key in params.keys():\n",
        "            self.h[key] *= self.decay_rate\n",
        "            self.h[key] += (1 - self.decay_rate) * grads[key] * grads[key]\n",
        "            params[key] -= self.lr * grads[key] / (np.sqrt(self.h[key]) + 1e-7)"
      ],
      "metadata": {
        "id": "4BYOwOFncq3S"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 가중치의 초깃값\n",
        "    1. 선형일 때 -> Xavier 초깃값 사용\n",
        "    2. ReLU를 사용할 때 -> He 초깃값 사용"
      ],
      "metadata": {
        "id": "IqHoDxDVdGAC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 배치 정규화\n",
        "    - Affine -> Batch Norm -> ReLU"
      ],
      "metadata": {
        "id": "__8RU3-EdXNc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 바른 학습을 위해\n",
        "    1. 오버피팅\n",
        "        - 가중치 감소 [ 손실 함수에 가중치의 L2노름을 더한 가중치 감소 방법 ]\n",
        "        - 드롭아웃 => 비슷한 효과를 내는 앙상블 학습도 있음"
      ],
      "metadata": {
        "id": "Xak_qxBDfedj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 적절한 하이퍼파라미터 값 찾기\n",
        "    - 데이터 분할\n",
        "        1. 훈련 데이터 : 매개변수 학습\n",
        "        2. 검증 데이터 : 하이퍼파라미터 성능 평가\n",
        "        3. 시험 데이터 : 신경망의 범묭 성능 평가\n",
        "    \n",
        "    - 하이퍼파라미터 최적화\n",
        "        - 그리드 서치보다는 무작위로 샘플링해 탐색하는 편이 좋다고 알려짐"
      ],
      "metadata": {
        "id": "oiWz53gJhk1i"
      }
    }
  ]
}